{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/V-Sekai-fire/meshgpt-pytorch/blob/main/MeshGPT_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTLGOz_qqEpp"
      },
      "source": [
        "We use a local runtime. https://research.google.com/colaboratory/local-runtimes.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "soJKTsx9qE7B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting git+https://github.com/MarcusLoppe/classifier-free-guidance-pytorch.git\n",
            "  Cloning https://github.com/MarcusLoppe/classifier-free-guidance-pytorch.git to /tmp/pip-req-build-9x6kw04p\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/MarcusLoppe/classifier-free-guidance-pytorch.git /tmp/pip-req-build-9x6kw04p\n",
            "  Resolved https://github.com/MarcusLoppe/classifier-free-guidance-pytorch.git to commit 698c83562f8859c763880f200b210ff1081efedc\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: beartype in /home/ernest.lee/.local/lib/python3.11/site-packages (from classifier-free-guidance-pytorch==0.5.2) (0.18.5)\n",
            "Requirement already satisfied: einops>=0.7 in /home/ernest.lee/.local/lib/python3.11/site-packages (from classifier-free-guidance-pytorch==0.5.2) (0.8.0)\n",
            "Requirement already satisfied: ftfy in /home/ernest.lee/.local/lib/python3.11/site-packages (from classifier-free-guidance-pytorch==0.5.2) (6.2.0)\n",
            "Requirement already satisfied: open-clip-torch>=2.8.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from classifier-free-guidance-pytorch==0.5.2) (2.24.0)\n",
            "Requirement already satisfied: torch>=2.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from classifier-free-guidance-pytorch==0.5.2) (2.3.0)\n",
            "Requirement already satisfied: transformers[torch] in /home/ernest.lee/.local/lib/python3.11/site-packages (from classifier-free-guidance-pytorch==0.5.2) (4.40.1)\n",
            "Requirement already satisfied: torchvision in /home/ernest.lee/.local/lib/python3.11/site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch==0.5.2) (0.18.0)\n",
            "Requirement already satisfied: regex in /home/ernest.lee/.local/lib/python3.11/site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch==0.5.2) (2024.4.28)\n",
            "Requirement already satisfied: tqdm in /home/ernest.lee/.local/lib/python3.11/site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch==0.5.2) (4.66.4)\n",
            "Requirement already satisfied: huggingface-hub in /home/ernest.lee/.local/lib/python3.11/site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch==0.5.2) (0.23.0)\n",
            "Requirement already satisfied: sentencepiece in /home/ernest.lee/.local/lib/python3.11/site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch==0.5.2) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /home/ernest.lee/.local/lib/python3.11/site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch==0.5.2) (5.26.1)\n",
            "Requirement already satisfied: timm in /home/ernest.lee/.local/lib/python3.11/site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch==0.5.2) (0.9.16)\n",
            "Requirement already satisfied: filelock in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (4.11.0)\n",
            "Requirement already satisfied: sympy in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (1.12)\n",
            "Requirement already satisfied: networkx in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ernest.lee/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (12.4.127)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /home/ernest.lee/.local/lib/python3.11/site-packages (from ftfy->classifier-free-guidance-pytorch==0.5.2) (0.2.13)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/ernest.lee/.local/lib/python3.11/site-packages (from transformers[torch]->classifier-free-guidance-pytorch==0.5.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from transformers[torch]->classifier-free-guidance-pytorch==0.5.2) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/ernest.lee/.local/lib/python3.11/site-packages (from transformers[torch]->classifier-free-guidance-pytorch==0.5.2) (6.0)\n",
            "Requirement already satisfied: requests in /home/ernest.lee/.local/lib/python3.11/site-packages (from transformers[torch]->classifier-free-guidance-pytorch==0.5.2) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ernest.lee/.local/lib/python3.11/site-packages (from transformers[torch]->classifier-free-guidance-pytorch==0.5.2) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/ernest.lee/.local/lib/python3.11/site-packages (from transformers[torch]->classifier-free-guidance-pytorch==0.5.2) (0.4.3)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from transformers[torch]->classifier-free-guidance-pytorch==0.5.2) (0.30.0)\n",
            "Requirement already satisfied: psutil in /home/ernest.lee/.local/lib/python3.11/site-packages (from accelerate>=0.21.0->transformers[torch]->classifier-free-guidance-pytorch==0.5.2) (5.9.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from jinja2->torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ernest.lee/.local/lib/python3.11/site-packages (from requests->transformers[torch]->classifier-free-guidance-pytorch==0.5.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/ernest.lee/.local/lib/python3.11/site-packages (from requests->transformers[torch]->classifier-free-guidance-pytorch==0.5.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ernest.lee/.local/lib/python3.11/site-packages (from requests->transformers[torch]->classifier-free-guidance-pytorch==0.5.2) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ernest.lee/.local/lib/python3.11/site-packages (from requests->transformers[torch]->classifier-free-guidance-pytorch==0.5.2) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/ernest.lee/.local/lib/python3.11/site-packages (from sympy->torch>=2.0->classifier-free-guidance-pytorch==0.5.2) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torchvision->open-clip-torch>=2.8.0->classifier-free-guidance-pytorch==0.5.2) (10.3.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n",
            "  Cloning https://github.com/MarcusLoppe/meshgpt-pytorch.git to /tmp/pip-req-build-jps2jo13\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/MarcusLoppe/meshgpt-pytorch.git /tmp/pip-req-build-jps2jo13\n",
            "  Resolved https://github.com/MarcusLoppe/meshgpt-pytorch.git to commit 780431bdba9a9c32be773967e57fdaf61739e1d5\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: accelerate>=0.25.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from meshgpt-pytorch==1.1.0) (0.30.0)\n",
            "Requirement already satisfied: beartype in /home/ernest.lee/.local/lib/python3.11/site-packages (from meshgpt-pytorch==1.1.0) (0.18.5)\n",
            "Requirement already satisfied: classifier-free-guidance-pytorch>=0.5.1 in /home/ernest.lee/.local/lib/python3.11/site-packages (from meshgpt-pytorch==1.1.0) (0.5.2)\n",
            "Requirement already satisfied: einops>=0.7.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from meshgpt-pytorch==1.1.0) (0.8.0)\n",
            "Requirement already satisfied: einx[torch]>=0.1.3 in /home/ernest.lee/.local/lib/python3.11/site-packages (from meshgpt-pytorch==1.1.0) (0.2.2)\n",
            "Requirement already satisfied: ema-pytorch in /home/ernest.lee/.local/lib/python3.11/site-packages (from meshgpt-pytorch==1.1.0) (0.4.5)\n",
            "Requirement already satisfied: local-attention>=1.9.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from meshgpt-pytorch==1.1.0) (1.9.1)\n",
            "Requirement already satisfied: gateloop-transformer>=0.2.2 in /home/ernest.lee/.local/lib/python3.11/site-packages (from meshgpt-pytorch==1.1.0) (0.2.4)\n",
            "Requirement already satisfied: numpy in /home/ernest.lee/.local/lib/python3.11/site-packages (from meshgpt-pytorch==1.1.0) (1.26.4)\n",
            "Requirement already satisfied: pytorch-custom-utils>=0.0.9 in /home/ernest.lee/.local/lib/python3.11/site-packages (from meshgpt-pytorch==1.1.0) (0.0.18)\n",
            "Requirement already satisfied: taylor-series-linear-attention>=0.1.6 in /home/ernest.lee/.local/lib/python3.11/site-packages (from meshgpt-pytorch==1.1.0) (0.1.9)\n",
            "Requirement already satisfied: torch>=2.1 in /home/ernest.lee/.local/lib/python3.11/site-packages (from meshgpt-pytorch==1.1.0) (2.3.0)\n",
            "Requirement already satisfied: torch_geometric in /home/ernest.lee/.local/lib/python3.11/site-packages (from meshgpt-pytorch==1.1.0) (2.5.3)\n",
            "Requirement already satisfied: torchtyping in /home/ernest.lee/.local/lib/python3.11/site-packages (from meshgpt-pytorch==1.1.0) (0.1.4)\n",
            "Requirement already satisfied: tqdm in /home/ernest.lee/.local/lib/python3.11/site-packages (from meshgpt-pytorch==1.1.0) (4.66.4)\n",
            "Requirement already satisfied: vector-quantize-pytorch>=1.12.8 in /home/ernest.lee/.local/lib/python3.11/site-packages (from meshgpt-pytorch==1.1.0) (1.14.12)\n",
            "Requirement already satisfied: x-transformers>=1.26.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from meshgpt-pytorch==1.1.0) (1.28.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.1.0) (24.0)\n",
            "Requirement already satisfied: psutil in /home/ernest.lee/.local/lib/python3.11/site-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.1.0) (5.9.8)\n",
            "Requirement already satisfied: pyyaml in /home/ernest.lee/.local/lib/python3.11/site-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.1.0) (6.0)\n",
            "Requirement already satisfied: huggingface-hub in /home/ernest.lee/.local/lib/python3.11/site-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.1.0) (0.23.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/ernest.lee/.local/lib/python3.11/site-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.1.0) (0.4.3)\n",
            "Requirement already satisfied: ftfy in /home/ernest.lee/.local/lib/python3.11/site-packages (from classifier-free-guidance-pytorch>=0.5.1->meshgpt-pytorch==1.1.0) (6.2.0)\n",
            "Requirement already satisfied: open-clip-torch>=2.8.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from classifier-free-guidance-pytorch>=0.5.1->meshgpt-pytorch==1.1.0) (2.24.0)\n",
            "Requirement already satisfied: transformers[torch] in /home/ernest.lee/.local/lib/python3.11/site-packages (from classifier-free-guidance-pytorch>=0.5.1->meshgpt-pytorch==1.1.0) (4.40.1)\n",
            "Requirement already satisfied: sympy in /home/ernest.lee/.local/lib/python3.11/site-packages (from einx[torch]>=0.1.3->meshgpt-pytorch==1.1.0) (1.12)\n",
            "Requirement already satisfied: frozendict in /home/ernest.lee/.local/lib/python3.11/site-packages (from einx[torch]>=0.1.3->meshgpt-pytorch==1.1.0) (2.4.3)\n",
            "Requirement already satisfied: rotary-embedding-torch in /home/ernest.lee/.local/lib/python3.11/site-packages (from gateloop-transformer>=0.2.2->meshgpt-pytorch==1.1.0) (0.5.3)\n",
            "Requirement already satisfied: optree in /home/ernest.lee/.local/lib/python3.11/site-packages (from pytorch-custom-utils>=0.0.9->meshgpt-pytorch==1.1.0) (0.11.0)\n",
            "Requirement already satisfied: pytorch-warmup in /home/ernest.lee/.local/lib/python3.11/site-packages (from pytorch-custom-utils>=0.0.9->meshgpt-pytorch==1.1.0) (0.1.1)\n",
            "Requirement already satisfied: filelock in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.1->meshgpt-pytorch==1.1.0) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.1->meshgpt-pytorch==1.1.0) (4.11.0)\n",
            "Requirement already satisfied: networkx in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.1->meshgpt-pytorch==1.1.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.1->meshgpt-pytorch==1.1.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.1->meshgpt-pytorch==1.1.0) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.1->meshgpt-pytorch==1.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.1->meshgpt-pytorch==1.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.1->meshgpt-pytorch==1.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.1->meshgpt-pytorch==1.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.1->meshgpt-pytorch==1.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.1->meshgpt-pytorch==1.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.1->meshgpt-pytorch==1.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.1->meshgpt-pytorch==1.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.1->meshgpt-pytorch==1.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.1->meshgpt-pytorch==1.1.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.1->meshgpt-pytorch==1.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch>=2.1->meshgpt-pytorch==1.1.0) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ernest.lee/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1->meshgpt-pytorch==1.1.0) (12.4.127)\n",
            "Requirement already satisfied: scipy in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch_geometric->meshgpt-pytorch==1.1.0) (1.13.0)\n",
            "Requirement already satisfied: aiohttp in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch_geometric->meshgpt-pytorch==1.1.0) (3.9.5)\n",
            "Requirement already satisfied: requests in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch_geometric->meshgpt-pytorch==1.1.0) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch_geometric->meshgpt-pytorch==1.1.0) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /home/ernest.lee/.local/lib/python3.11/site-packages (from torch_geometric->meshgpt-pytorch==1.1.0) (1.4.2)\n",
            "Requirement already satisfied: typeguard>=2.11.1 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torchtyping->meshgpt-pytorch==1.1.0) (4.2.1)\n",
            "Requirement already satisfied: torchvision in /home/ernest.lee/.local/lib/python3.11/site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.5.1->meshgpt-pytorch==1.1.0) (0.18.0)\n",
            "Requirement already satisfied: regex in /home/ernest.lee/.local/lib/python3.11/site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.5.1->meshgpt-pytorch==1.1.0) (2024.4.28)\n",
            "Requirement already satisfied: sentencepiece in /home/ernest.lee/.local/lib/python3.11/site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.5.1->meshgpt-pytorch==1.1.0) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /home/ernest.lee/.local/lib/python3.11/site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.5.1->meshgpt-pytorch==1.1.0) (5.26.1)\n",
            "Requirement already satisfied: timm in /home/ernest.lee/.local/lib/python3.11/site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.5.1->meshgpt-pytorch==1.1.0) (0.9.16)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/ernest.lee/.local/lib/python3.11/site-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.1.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.1.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/ernest.lee/.local/lib/python3.11/site-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.1.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ernest.lee/.local/lib/python3.11/site-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.1.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.1.0) (1.9.4)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /home/ernest.lee/.local/lib/python3.11/site-packages (from ftfy->classifier-free-guidance-pytorch>=0.5.1->meshgpt-pytorch==1.1.0) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from jinja2->torch>=2.1->meshgpt-pytorch==1.1.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ernest.lee/.local/lib/python3.11/site-packages (from requests->torch_geometric->meshgpt-pytorch==1.1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/ernest.lee/.local/lib/python3.11/site-packages (from requests->torch_geometric->meshgpt-pytorch==1.1.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ernest.lee/.local/lib/python3.11/site-packages (from requests->torch_geometric->meshgpt-pytorch==1.1.0) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ernest.lee/.local/lib/python3.11/site-packages (from requests->torch_geometric->meshgpt-pytorch==1.1.0) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from scikit-learn->torch_geometric->meshgpt-pytorch==1.1.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from scikit-learn->torch_geometric->meshgpt-pytorch==1.1.0) (3.5.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/ernest.lee/.local/lib/python3.11/site-packages (from sympy->einx[torch]>=0.1.3->meshgpt-pytorch==1.1.0) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ernest.lee/.local/lib/python3.11/site-packages (from transformers[torch]->classifier-free-guidance-pytorch>=0.5.1->meshgpt-pytorch==1.1.0) (0.19.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from torchvision->open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.5.1->meshgpt-pytorch==1.1.0) (10.3.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: trimesh in /home/ernest.lee/.local/lib/python3.11/site-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /home/ernest.lee/.local/lib/python3.11/site-packages (from trimesh) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "#!bash <(curl -L micro.mamba.pm/install.sh) \n",
        "#Prefix location? [~/micromamba] /workspace/micromamba\n",
        "#!pip3 install notebook jupyterlab\n",
        "#!micromamba create -n py311_meshgpt python=3.11 anaconda -c pytorch -c conda-forge -c anaconda -c defaults -y\n",
        "#!micromamba activate py311_meshgpt\n",
        "#!jupyter notebook --port=9999  --NotebookApp.port_retries=0 --allow-root\n",
        "# Login with kernel\n",
        "!pip3 install git+https://github.com/MarcusLoppe/classifier-free-guidance-pytorch.git\n",
        "!pip3 install git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n",
        "!pip3 install trimesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NM_rRocQAcZ_"
      },
      "outputs": [],
      "source": [
        "from re import T\n",
        "is_train_autoencoder = False\n",
        "is_train_autoencoder_disable_iteration = False\n",
        "is_train_mesh_transformer = True\n",
        "is_clear_dataset_npz = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5ztZ1JUl8zOZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import trimesh\n",
        "import numpy as np\n",
        "import os\n",
        "import csv\n",
        "from collections import OrderedDict\n",
        "\n",
        "from meshgpt_pytorch import (\n",
        "    MeshTransformerTrainer,\n",
        "    MeshAutoencoderTrainer,\n",
        "    MeshAutoencoder,\n",
        "    MeshTransformer\n",
        ")\n",
        "from meshgpt_pytorch.data import (\n",
        "    derive_face_edges_from_faces\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "7aW7oUHedRmQ"
      },
      "outputs": [],
      "source": [
        "import trimesh\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "\n",
        "max_faces = 4096\n",
        "\n",
        "def get_mesh(file_path):\n",
        "    mesh = trimesh.load(file_path, force='mesh')\n",
        "\n",
        "    # Center and scale vertices\n",
        "    center = np.mean(mesh.vertices, axis=0)\n",
        "    vertices = mesh.vertices - center\n",
        "    max_abs = np.max(np.abs(vertices))\n",
        "    scale_factor = (1 / 128) / max_abs\n",
        "    vertices *= scale_factor\n",
        "\n",
        "    # Quantize vertices\n",
        "    vertices = np.around(vertices).astype(np.float32)\n",
        "\n",
        "    # Sort vertices by Z, Y, X\n",
        "    sorted_indices = np.lexsort(vertices.T[::-1])\n",
        "    vertices = vertices[sorted_indices]\n",
        "\n",
        "    # Map old indices to new, sorted indices\n",
        "    vertex_map = np.empty(len(sorted_indices), dtype=int)\n",
        "    vertex_map[sorted_indices] = np.arange(len(sorted_indices))\n",
        "\n",
        "    # Reindex faces\n",
        "    reindexed_faces = vertex_map[mesh.faces]\n",
        "    sorted_faces = np.sort(reindexed_faces, axis=1)\n",
        "\n",
        "    return vertices, sorted_faces\n",
        "\n",
        "def augment_mesh(vertices, jitter_strength=0.01):\n",
        "    jitter_amount = np.random.uniform(-jitter_strength, jitter_strength, size=vertices.shape)\n",
        "    vertices += jitter_amount\n",
        "    return vertices\n",
        "\n",
        "def snake_to_sentence_case(snake_str):\n",
        "    components = snake_str.split(\"_\")\n",
        "    return \" \".join(word.capitalize() for word in components)\n",
        "\n",
        "def load_filename(directory, variations):\n",
        "    obj_datas = []\n",
        "\n",
        "    # Get random scale factors within a range\n",
        "    scale_factors = np.random.uniform(0.75, 1.0, size=variations)\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".glb\"):\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            vertices, faces = get_mesh(file_path)\n",
        "\n",
        "            if len(faces) > max_faces:\n",
        "                print(f\"Mesh {filename} has {len(faces)} faces which is more than the allowed {max_faces} faces. Rejecting.\")\n",
        "                continue\n",
        "\n",
        "            faces_tensor = torch.tensor(faces, dtype=torch.long).to(\"cuda\")\n",
        "            face_edges = derive_face_edges_from_faces(faces_tensor)\n",
        "\n",
        "            text, _ = os.path.splitext(filename)\n",
        "            text = snake_to_sentence_case(text)\n",
        "            # Run video llava on the image. \"Describe the focus of the photo as a json dictionary.\"\n",
        "            for scale_factor in scale_factors:\n",
        "                aug_vertices = augment_mesh(vertices.copy()) * scale_factor\n",
        "                aug_vertices_tensor = torch.tensor(aug_vertices, dtype=torch.float)\n",
        "\n",
        "            obj_data = {\n",
        "                \"vertices\": aug_vertices_tensor.to(\"cuda\"),\n",
        "                \"faces\": faces_tensor,\n",
        "                \"face_edges\": face_edges,\n",
        "                \"texts\": text\n",
        "            }\n",
        "            obj_datas.append(obj_data)\n",
        "\n",
        "    print(f\"[create_mesh_dataset] Returning {len(obj_datas)} meshes\")\n",
        "    return obj_datas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "vthmcnU2dRmS",
        "outputId": "9cdca85c-3350-4c4d-869b-d82685259942"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mesh s_chair_office.glb has 6894 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh s_chair_office_01.glb has 25192 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh s_desk.glb has 7240 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh s_door_double.glb has 4424 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh s_form_torso_dress_feminine.glb has 21754 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh s_sgcontroller.glb has 8848 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh s_skate_park.glb has 8598 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh s_table_coffee.glb has 4304 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh s_table_coffee_variation.glb has 8140 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh s_vehicle_bicycle_bmx.glb has 39972 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh sk_baby_01.glb has 13408 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh sk_child_01.glb has 13408 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh sk_dog_01.glb has 8418 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh sk_feminine_adult.glb has 13358 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh sk_feminine_teen.glb has 13358 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh sk_horse_01.glb has 4447 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh sk_masculine_adult.glb has 13410 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh sk_masculine_adult_ik.glb has 13410 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "Mesh sk_masculine_teen.glb has 13408 faces which is more than the allowed 4096 faces. Rejecting.\n",
            "[create_mesh_dataset] Returning 44 meshes\n",
            "[MeshDataset] Created from 44 entrys\n",
            "[MeshDataset] Generated face_edges for 0/44 entrys\n",
            "[MeshDataset] Saved 44 entrys at dataset/blockmesh_test/meshgpt-pytorch.npz\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import gc\n",
        "import torch\n",
        "import os\n",
        "from meshgpt_pytorch import MeshDataset\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "project_name = \"meshgpt-pytorch\"\n",
        "\n",
        "working_dir = f'dataset/blockmesh_test'\n",
        "\n",
        "working_dir = Path(working_dir)\n",
        "working_dir.mkdir(exist_ok = True, parents = True)\n",
        "dataset_path = working_dir / (project_name + \".npz\")\n",
        "\n",
        "\n",
        "if is_clear_dataset_npz:\n",
        "    data = load_filename(working_dir, 1)\n",
        "    dataset = MeshDataset(data)\n",
        "    dataset.generate_face_edges()\n",
        "    dataset.save(dataset_path)\n",
        "else:\n",
        "    dataset = MeshDataset.load(dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzVsRDtzdRmT"
      },
      "source": [
        "### Inspect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "vPpalWsbdRmU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 0 complete. Processed texts Mire Clothing with 2179 vertices and 3884 faces.\n",
            "Iteration 1 complete. Processed texts S Bed Full with 62 vertices and 48 faces.\n",
            "Iteration 2 complete. Processed texts S Bed King with 403 vertices and 480 faces.\n",
            "Iteration 3 complete. Processed texts S Bed Twin with 403 vertices and 480 faces.\n",
            "Iteration 4 complete. Processed texts S Bone with 56 vertices and 24 faces.\n",
            "Iteration 5 complete. Processed texts S Box with 24 vertices and 12 faces.\n",
            "Iteration 6 complete. Processed texts S Cabinet Bookshelf with 690 vertices and 512 faces.\n",
            "Iteration 7 complete. Processed texts S Cabinet Dresser 03 with 552 vertices and 256 faces.\n",
            "Iteration 8 complete. Processed texts S Cabinet Dresser 05 with 744 vertices and 344 faces.\n",
            "Iteration 9 complete. Processed texts S Chair Bar with 385 vertices and 440 faces.\n",
            "Iteration 10 complete. Processed texts S Chair Box with 1848 vertices and 912 faces.\n",
            "Iteration 11 complete. Processed texts S Chair Modern with 904 vertices and 1176 faces.\n",
            "Iteration 12 complete. Processed texts S Chair Sofa with 1142 vertices and 1464 faces.\n",
            "Iteration 13 complete. Processed texts S Chair Sofa Wide with 702 vertices and 784 faces.\n",
            "Iteration 14 complete. Processed texts S Chair Stool with 848 vertices and 564 faces.\n",
            "Iteration 15 complete. Processed texts S Chair Stool Mini with 637 vertices and 564 faces.\n",
            "Iteration 16 complete. Processed texts S Door Double Frame with 38 vertices and 44 faces.\n",
            "Iteration 17 complete. Processed texts S Door Single with 1917 vertices and 2320 faces.\n",
            "Iteration 18 complete. Processed texts S Door Single Frame with 38 vertices and 44 faces.\n",
            "Iteration 19 complete. Processed texts S Gui with 40 vertices and 20 faces.\n",
            "Iteration 20 complete. Processed texts S Hmd with 451 vertices and 626 faces.\n",
            "Iteration 21 complete. Processed texts S Mask with 1089 vertices and 2090 faces.\n",
            "Iteration 22 complete. Processed texts S Phone with 1280 vertices and 1306 faces.\n",
            "Iteration 23 complete. Processed texts S Primitive Cylinder with 130 vertices and 128 faces.\n",
            "Iteration 24 complete. Processed texts S Primitive Cylinder Hollow with 128 vertices and 256 faces.\n",
            "Iteration 25 complete. Processed texts S Primitive Pyramid with 16 vertices and 6 faces.\n",
            "Iteration 26 complete. Processed texts S Primitive Sphere with 205 vertices and 320 faces.\n",
            "Iteration 27 complete. Processed texts S Primitive Wedge with 18 vertices and 8 faces.\n",
            "Iteration 28 complete. Processed texts S Stairs Single-6 with 96 vertices and 48 faces.\n",
            "Iteration 29 complete. Processed texts S Table Bar with 432 vertices and 216 faces.\n",
            "Iteration 30 complete. Processed texts S Table Bar Circle with 1486 vertices and 1376 faces.\n",
            "Iteration 31 complete. Processed texts S Table Bar Rectangle with 216 vertices and 108 faces.\n",
            "Iteration 32 complete. Processed texts S Table Bedside with 2388 vertices and 2184 faces.\n",
            "Iteration 33 complete. Processed texts S Table Counter with 96 vertices and 48 faces.\n",
            "Iteration 34 complete. Processed texts S Table Nightstand with 336 vertices and 168 faces.\n",
            "Iteration 35 complete. Processed texts S Table Office with 3112 vertices and 1556 faces.\n",
            "Iteration 36 complete. Processed texts S Table Sit Circle with 1486 vertices and 1376 faces.\n",
            "Iteration 37 complete. Processed texts S Table Sit Rectangle with 168 vertices and 144 faces.\n",
            "Iteration 38 complete. Processed texts S Table Sit Square with 168 vertices and 144 faces.\n",
            "Iteration 39 complete. Processed texts S Tree Bushy with 796 vertices and 910 faces.\n",
            "Iteration 40 complete. Processed texts S Tree No Leaves with 1197 vertices and 1486 faces.\n",
            "Iteration 41 complete. Processed texts S Ziggurat with 264 vertices and 335 faces.\n",
            "Iteration 42 complete. Processed texts Sk Cat 01 with 2074 vertices and 3638 faces.\n",
            "Iteration 43 complete. Processed texts Sk Snake 01 with 280 vertices and 556 faces.\n",
            "Total number of processed meshes: 44\n"
          ]
        }
      ],
      "source": [
        "seen_texts = []\n",
        "mesh_list = []  # List to store individual meshes\n",
        "translation_distance = 1.0  # Distance to translate vertices, set to 1 unit as required\n",
        "\n",
        "# Iterate over each item in the dataset\n",
        "for r, item in enumerate(dataset.data):\n",
        "    # Get vertices and faces\n",
        "    vertices = np.array(item['vertices'].cpu())\n",
        "    faces = np.array(item['faces'].cpu())\n",
        "    texts = item['texts']\n",
        "\n",
        "    if texts in seen_texts:\n",
        "      continue\n",
        "    seen_texts.append(texts)\n",
        "\n",
        "    # Translate the vertices copy\n",
        "    translation_vector = np.array([len(seen_texts) * translation_distance, 0, 0])  # Translation along the x-axis\n",
        "    vertices[:, :3] += translation_vector  # Apply translation only to x, y, z\n",
        "\n",
        "    # Create a new mesh object with the translated vertices and original faces\n",
        "    mesh = trimesh.Trimesh(vertices=vertices, faces=faces)\n",
        "\n",
        "    # Append the new mesh to our list of meshes\n",
        "    mesh_list.append(mesh)\n",
        "\n",
        "    print(f\"Iteration {r} complete. Processed texts {texts} with {len(vertices)} vertices and {len(faces)} faces.\")\n",
        "\n",
        "# After iterating over all items, print the number of processed meshes\n",
        "print(f\"Total number of processed meshes: {len(mesh_list)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4pHZ20udRmU"
      },
      "source": [
        "### Train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "xoAxJWecdRmV"
      },
      "outputs": [],
      "source": [
        "autoencoder = MeshAutoencoder().to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlJewvY1dRmV"
      },
      "source": [
        "**Have at least 400-2000 items in the dataset, use this to multiply the dataset**  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "JJ9qMRVxdRmW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44\n",
            "400\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(dataset.data)\n",
        "\n",
        "initial_length = len(dataset.data)\n",
        "target_length = 400\n",
        "print(initial_length)\n",
        "if initial_length > 0:\n",
        "    replication_factor = max(1, (target_length - 1) // initial_length + 1)\n",
        "    dataset.data *= replication_factor\n",
        "    dataset.data = dataset.data[:target_length]\n",
        "\n",
        "print(len(dataset.data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9k-OAoBdRmY"
      },
      "source": [
        "**Train to about 0.3 loss if you are using a small dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "NKTuiTHvdRmY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[44], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m   autoencoder_trainer\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mworking_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/mesh-encoder_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m   \u001b[43mautoencoder_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mworking_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/mesh-encoder_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mproject_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m   autencoder \u001b[38;5;241m=\u001b[39m autoencoder_trainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m     13\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m autoencoder\u001b[38;5;241m.\u001b[39mparameters():\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/meshgpt_pytorch/trainer.py:235\u001b[0m, in \u001b[0;36mMeshAutoencoderTrainer.load\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[1;32m    234\u001b[0m     path \u001b[38;5;241m=\u001b[39m Path(path)\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists()\n\u001b[1;32m    237\u001b[0m     pkg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mstr\u001b[39m(path))\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(__version__) \u001b[38;5;241m!=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(pkg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "autoencoder_trainer = MeshAutoencoderTrainer(model = autoencoder ,warmup_steps = 10, dataset = dataset, num_train_steps=100,\n",
        "                                            batch_size=8,\n",
        "                                            grad_accum_every=2,\n",
        "                                            learning_rate = 4e-3)\n",
        "if is_train_autoencoder:\n",
        "  if not is_train_autoencoder_disable_iteration:\n",
        "    autoencoder_trainer.load(f'{working_dir}/mesh-encoder_{project_name}.pt')\n",
        "  loss = autoencoder_trainer.train(380,stop_at_loss = 0.28, diplay_graph= True)\n",
        "  autoencoder_trainer.save(f'{working_dir}/mesh-encoder_{project_name}.pt')\n",
        "else:\n",
        "  autoencoder_trainer.load(f'{working_dir}/mesh-encoder_{project_name}.pt')\n",
        "  autencoder = autoencoder_trainer.model\n",
        "  for param in autoencoder.parameters():\n",
        "      param.requires_grad = True\n",
        "  import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLCezPnNdRmZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Highest face count: 3884\n",
            "Max token sequence: 23304\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/micromamba/envs/py311_meshgpt/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decoder total parameters: 94.4M\n",
            "Total parameters: 152.6M\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "max_length =  max(len(d[\"faces\"]) for d in dataset if \"faces\" in d)\n",
        "max_seq = max_length * 6\n",
        "print(\"Highest face count:\" , max_length)\n",
        "print(\"Max token sequence:\" , max_seq)\n",
        "\n",
        "transformer = MeshTransformer(\n",
        "    autoencoder,\n",
        "    dim = 512,\n",
        "    coarse_pre_gateloop_depth = 6, # Better performance using more gateloop layers\n",
        "    fine_pre_gateloop_depth= 4,\n",
        "    #attn_depth = 24, # GPT-2 medium have 24 layer depth, change if needed\n",
        "    max_seq_len = max_seq,\n",
        "    condition_on_text = True,\n",
        "    gateloop_use_heinsen = False,\n",
        "    text_condition_model_types = \"bge\", ## Change or remove this line if you are using:  https://github.com/MarcusLoppe/classifier-free-guidance-pytorch\n",
        "    text_condition_cond_drop_prob = 0.0\n",
        ")\n",
        "\n",
        "total_params = sum(p.numel() for p in transformer.decoder.parameters())\n",
        "total_params = f\"{total_params / 1000000:.1f}M\"\n",
        "print(f\"Decoder total parameters: {total_params}\")\n",
        "total_params = sum(p.numel() for p in transformer.parameters())\n",
        "total_params = f\"{total_params / 1000000:.1f}M\"\n",
        "print(f\"Total parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tun8sv-udRmZ"
      },
      "source": [
        "## **Required!**, embed the text and run generate_codes to save 4-96 GB VRAM (dependant on dataset) ##\n",
        "\n",
        "**If you don't;** <br>\n",
        "During each during each training step the autoencoder will generate the codes and the text encoder will embed the text.\n",
        "<br>\n",
        "After these fields are generate: **they will be deleted and next time it generates the code again:**<br>\n",
        "\n",
        "This is due to the dataloaders nature, it writes this information to a temporary COPY of the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s--ya8W0dRmZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'S Chair Sofa', 'S Chair Bar', 'S Hmd', 'S Table Sit Square', 'S Chair Stool Mini', 'Mire Clothing', 'S Primitive Pyramid', 'S Chair Sofa Wide', 'S Bed Twin', 'S Door Single Frame', 'S Door Double Frame', 'S Cabinet Bookshelf', 'S Primitive Wedge', 'S Table Bar Rectangle', 'S Chair Stool', 'S Box', 'S Cabinet Dresser 05', 'S Primitive Cylinder', 'S Table Bar Circle', 'S Gui', 'S Bed King', 'S Table Nightstand', 'S Table Bedside', 'S Stairs Single-6', 'S Tree No Leaves', 'S Phone', 'S Bone', 'S Chair Modern', 'S Table Office', 'S Door Single', 'S Cabinet Dresser 03', 'S Bed Full', 'S Primitive Cylinder Hollow', 'S Primitive Sphere', 'Sk Snake 01', 'S Chair Box', 'S Table Counter', 'Sk Cat 01', 'S Table Bar', 'S Table Sit Circle', 'S Tree Bushy', 'S Mask', 'S Table Sit Rectangle', 'S Ziggurat'}\n",
            "[MeshDataset] Generated 44 text_embeddings\n",
            "[MeshDataset] Generated codes for 2000 entrys\n",
            "dict_keys(['vertices', 'faces', 'face_edges', 'text_embeds', 'codes'])\n"
          ]
        }
      ],
      "source": [
        "labels = set(item[\"texts\"] for item in dataset.data)\n",
        "print(labels)\n",
        "dataset.embed_texts(transformer)\n",
        "dataset.generate_codes(autoencoder)\n",
        "print(dataset.data[0].keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFa_p1G-dRma"
      },
      "source": [
        "*Load previous saved model if you had to restart session*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXZ0qgV3dRma"
      },
      "source": [
        "**Train to about 0.0001 loss (or less) if you are using a small dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TODO: Needs a fail early system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9hV_xUQdRma"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/7: 100%|| 2000/2000 [07:08<00:00,  4.66it/s, loss=7.4]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 average loss: 7.416166525118053\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/7: 100%|| 2000/2000 [07:09<00:00,  4.65it/s, loss=5.65]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 average loss: 4.328081157442182\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/7: 100%|| 2000/2000 [07:07<00:00,  4.68it/s, loss=0.0952]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 average loss: 2.25699469096493\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/7: 100%|| 2000/2000 [07:02<00:00,  4.73it/s, loss=0.0171]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 average loss: 0.9091332746301778          avg loss speed: 3.7579475165448777\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/7: 100%|| 2000/2000 [07:05<00:00,  4.70it/s, loss=0.436]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 average loss: 0.26045236000115984          avg loss speed: 2.2376173476779364\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/7: 100%|| 2000/2000 [07:09<00:00,  4.65it/s, loss=0.0254]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 average loss: 0.054236595172202216          avg loss speed: 1.0879568466932203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/7: 100%|| 2000/2000 [06:59<00:00,  4.76it/s, loss=0.00704]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 average loss: 0.012523111718823202          avg loss speed: 0.3954176315490234\n",
            "Stopping training at epoch 6 with average loss 0.012523111718823202\n",
            "Training complete\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "steps = 100\n",
        "trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=4,num_train_steps=steps, dataset = dataset,\n",
        "                                 learning_rate = 5e-4, batch_size=1)\n",
        "if is_train_mesh_transformer:\n",
        "  loss = trainer.train(steps, stop_at_loss = 0.02)\n",
        "else:\n",
        "  trainer.load(f'{working_dir}/mesh-transformer_{project_name}.pt')\n",
        "transformer = trainer.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save(f'{working_dir}\\mesh-transformer_{project_name}.pt')   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save(f'{working_dir}\\mesh-transformer_{project_name}.pt')   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI5IM_Z3K26g"
      },
      "source": [
        "**Load the latest model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8by6SXp4GHd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Highest face count: 3884\n",
            "Max token sequence: 23304\n"
          ]
        }
      ],
      "source": [
        "autoencoder_trainer = MeshAutoencoderTrainer(model = autoencoder ,warmup_steps = 10, dataset = dataset, num_train_steps=100, batch_size=1,  grad_accum_every=1, learning_rate = 1e-4)\n",
        "autoencoder_trainer.load(f'{working_dir}/mesh-encoder_{project_name}.pt')\n",
        "autencoder = autoencoder_trainer.model\n",
        "for param in autoencoder.parameters():\n",
        "    param.requires_grad = True\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "max_length =  max(len(d[\"faces\"]) for d in dataset if \"faces\" in d)\n",
        "max_seq = max_length * 6\n",
        "print(\"Highest face count:\" , max_length)\n",
        "print(\"Max token sequence:\" , max_seq)\n",
        "\n",
        "transformer = MeshTransformer(\n",
        "    autoencoder,\n",
        "    dim = 512,\n",
        "    coarse_pre_gateloop_depth = 6, # Better performance using more gateloop layers\n",
        "    fine_pre_gateloop_depth= 4,\n",
        "    # attn_depth = 24, # GPT-2 medium have 24 layer depth, change if needed\n",
        "    max_seq_len = max_seq,\n",
        "    condition_on_text = True,\n",
        "    gateloop_use_heinsen = False,\n",
        "    text_condition_model_types = \"bge\", ## Change or remove this line if you are using:  https://github.com/MarcusLoppe/classifier-free-guidance-pytorch\n",
        "    text_condition_cond_drop_prob = 0.0\n",
        ").to(\"cuda\")\n",
        "\n",
        "trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=1,num_train_steps=100, dataset = dataset, learning_rate = 1e-1, batch_size=2)\n",
        "trainer.load(f'{working_dir}\\mesh-transformer_{project_name}.pt')\n",
        "transformer = trainer.model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIn8JVsNdRma"
      },
      "source": [
        "## Generate and view mesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tX4RM2-ddRma"
      },
      "outputs": [],
      "source": [
        "def combind_mesh(path, mesh):\n",
        "    all_vertices = []\n",
        "    all_faces = []\n",
        "    vertex_offset = 0\n",
        "    translation_distance = 0.5\n",
        "\n",
        "    for r, faces_coordinates in enumerate(mesh):\n",
        "        numpy_data = faces_coordinates[0].cpu().numpy().reshape(-1, 3)\n",
        "\n",
        "        for vertex in numpy_data:\n",
        "            all_vertices.append(f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\")\n",
        "\n",
        "        for i in range(1, len(numpy_data), 3):\n",
        "            all_faces.append(f\"f {i + vertex_offset} {i + 1 + vertex_offset} {i + 2 + vertex_offset}\\n\")\n",
        "\n",
        "        vertex_offset += len(numpy_data)\n",
        "\n",
        "    obj_file_content = \"\".join(all_vertices) + \"\".join(all_faces)\n",
        "\n",
        "    with open(path , \"w\") as file:\n",
        "        file.write(obj_file_content)\n",
        "\n",
        "def combind_mesh_with_rows(path, meshes):\n",
        "    all_vertices = []\n",
        "    all_faces = []\n",
        "    vertex_offset = 0\n",
        "    translation_distance = 0.5\n",
        "\n",
        "    for row, mesh in enumerate(meshes):\n",
        "        for r, faces_coordinates in enumerate(mesh):\n",
        "            numpy_data = faces_coordinates[0].cpu().numpy().reshape(-1, 3)\n",
        "            numpy_data[:, 0] += translation_distance * (r / 0.2 - 1)\n",
        "            numpy_data[:, 2] += translation_distance * (row / 0.2 - 1)\n",
        "\n",
        "            for vertex in numpy_data:\n",
        "                all_vertices.append(f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\")\n",
        "\n",
        "            for i in range(1, len(numpy_data), 3):\n",
        "                all_faces.append(f\"f {i + vertex_offset} {i + 1 + vertex_offset} {i + 2 + vertex_offset}\\n\")\n",
        "\n",
        "            vertex_offset += len(numpy_data)\n",
        "\n",
        "        obj_file_content = \"\".join(all_vertices) + \"\".join(all_faces)\n",
        "\n",
        "    with open(path , \"w\") as file:\n",
        "        file.write(obj_file_content)\n",
        "\n",
        "\n",
        "def write_mesh_output(path, coords):\n",
        "    numpy_data = faces_coordinates[0].cpu().numpy().reshape(-1, 3)\n",
        "    obj_file_content = \"\"\n",
        "\n",
        "    for vertex in numpy_data:\n",
        "        obj_file_content += f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\"\n",
        "\n",
        "    for i in range(1, len(numpy_data), 3):\n",
        "        obj_file_content += f\"f {i} {i + 1} {i + 2}\\n\"\n",
        "\n",
        "    with open(path, \"w\") as file:\n",
        "        file.write(obj_file_content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdd-0bMJdRma"
      },
      "source": [
        "**Using only text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzAkhWM7dRmb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating S Chair Sofa\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|                                                                                                  | 10056/23304 [01:08<01:30, 146.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating S Chair Bar\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 23304/23304 [02:39<00:00, 146.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating S Hmd\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 23304/23304 [02:38<00:00, 147.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating S Table Sit Square\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|                                                                                                                                                    | 2784/23304 [00:18<02:17, 149.66it/s]"
          ]
        }
      ],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "\n",
        "folder = working_dir / 'renders'\n",
        "obj_file_path = Path(folder)\n",
        "obj_file_path.mkdir(exist_ok = True, parents = True)\n",
        "\n",
        "text_coords = []\n",
        "for text in labels:\n",
        "    print(f\"Generating {text}\")\n",
        "    faces_coordinates = transformer.generate(texts = [text],  temperature = 0.0)\n",
        "    text_coords.append(faces_coordinates)\n",
        "\n",
        "    write_mesh_output(f'{folder}/3d_output_{text}.obj', faces_coordinates)\n",
        "\n",
        "\n",
        "combind_mesh(f'{folder}/3d_models_all.obj', text_coords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFaqEK_I8xDU"
      },
      "source": [
        "# **Preview 3d Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "C0xYQqQZ81nw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting ipyvolume\n",
            "  Downloading ipyvolume-0.6.3-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: trimesh in /home/ernest.lee/.local/lib/python3.11/site-packages (4.3.2)\n",
            "Collecting pythreejs\n",
            "  Downloading pythreejs-2.4.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hCollecting ipywidgets>=7.0.0\n",
            "  Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bqplot\n",
            "  Downloading bqplot-0.12.43-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /home/ernest.lee/.local/lib/python3.11/site-packages (from ipyvolume) (1.26.4)\n",
            "Collecting traittypes\n",
            "  Downloading traittypes-0.2.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: traitlets in /home/ernest.lee/.local/lib/python3.11/site-packages (from ipyvolume) (5.14.3)\n",
            "Requirement already satisfied: Pillow in /home/ernest.lee/.local/lib/python3.11/site-packages (from ipyvolume) (10.3.0)\n",
            "Collecting ipywebrtc\n",
            "  Downloading ipywebrtc-0.6.0-py2.py3-none-any.whl (260 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m260.7/260.7 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /home/ernest.lee/.local/lib/python3.11/site-packages (from ipyvolume) (2.31.0)\n",
            "Collecting ipyvuetify\n",
            "  Downloading ipyvuetify-1.9.4-py2.py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hCollecting ipyvue>=1.7.0\n",
            "  Downloading ipyvue-1.11.1-py2.py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /home/ernest.lee/.local/lib/python3.11/site-packages (from ipyvolume) (3.8.4)\n",
            "Collecting ipydatawidgets>=1.1.1\n",
            "  Downloading ipydatawidgets-4.3.5-py2.py3-none-any.whl (271 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m271.7/271.7 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: comm>=0.1.3 in /home/ernest.lee/.local/lib/python3.11/site-packages (from ipywidgets>=7.0.0->ipyvolume) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from ipywidgets>=7.0.0->ipyvolume) (8.24.0)\n",
            "Collecting widgetsnbextension~=4.0.10\n",
            "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hCollecting jupyterlab-widgets~=3.0.10\n",
            "  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m215.0/215.0 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0.0,>=1.0.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from bqplot->ipyvolume) (2.1.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/ernest.lee/.local/lib/python3.11/site-packages (from matplotlib->ipyvolume) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/ernest.lee/.local/lib/python3.11/site-packages (from matplotlib->ipyvolume) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from matplotlib->ipyvolume) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ernest.lee/.local/lib/python3.11/site-packages (from matplotlib->ipyvolume) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from matplotlib->ipyvolume) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/ernest.lee/.local/lib/python3.11/site-packages (from matplotlib->ipyvolume) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/ernest.lee/.local/lib/python3.11/site-packages (from matplotlib->ipyvolume) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ernest.lee/.local/lib/python3.11/site-packages (from requests->ipyvolume) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/ernest.lee/.local/lib/python3.11/site-packages (from requests->ipyvolume) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ernest.lee/.local/lib/python3.11/site-packages (from requests->ipyvolume) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ernest.lee/.local/lib/python3.11/site-packages (from requests->ipyvolume) (2024.2.2)\n",
            "Requirement already satisfied: decorator in /home/ernest.lee/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->ipyvolume) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /home/ernest.lee/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->ipyvolume) (0.19.1)\n",
            "Requirement already satisfied: matplotlib-inline in /home/ernest.lee/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->ipyvolume) (0.1.7)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/ernest.lee/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->ipyvolume) (3.0.43)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->ipyvolume) (2.18.0)\n",
            "Requirement already satisfied: stack-data in /home/ernest.lee/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->ipyvolume) (0.6.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /home/ernest.lee/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->ipyvolume) (4.11.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /home/ernest.lee/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->ipyvolume) (4.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/ernest.lee/.local/lib/python3.11/site-packages (from pandas<3.0.0,>=1.0.0->bqplot->ipyvolume) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/ernest.lee/.local/lib/python3.11/site-packages (from pandas<3.0.0,>=1.0.0->bqplot->ipyvolume) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/ernest.lee/.local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->ipyvolume) (1.16.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/ernest.lee/.local/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.0.0->ipyvolume) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /home/ernest.lee/.local/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=7.0.0->ipyvolume) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /home/ernest.lee/.local/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets>=7.0.0->ipyvolume) (0.2.13)\n",
            "Requirement already satisfied: executing>=1.2.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->ipyvolume) (2.0.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /home/ernest.lee/.local/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->ipyvolume) (2.4.1)\n",
            "Requirement already satisfied: pure-eval in /home/ernest.lee/.local/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->ipyvolume) (0.2.2)\n",
            "Installing collected packages: ipywebrtc, widgetsnbextension, traittypes, jupyterlab-widgets, ipywidgets, ipyvue, ipydatawidgets, bqplot, pythreejs, ipyvuetify, ipyvolume\n",
            "Successfully installed bqplot-0.12.43 ipydatawidgets-4.3.5 ipyvolume-0.6.3 ipyvue-1.11.1 ipyvuetify-1.9.4 ipywebrtc-0.6.0 ipywidgets-8.1.2 jupyterlab-widgets-3.0.10 pythreejs-2.4.2 traittypes-0.2.1 widgetsnbextension-4.0.10\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "string is not a file: dataset/blockmesh_test/renders/3d_models_all.obj",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[45], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtrimesh\u001b[39;00m\n\u001b[1;32m      4\u001b[0m folder \u001b[38;5;241m=\u001b[39m working_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrenders\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m mesh \u001b[38;5;241m=\u001b[39m \u001b[43mtrimesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfolder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/3d_models_all.obj\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mipyvolume\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mipv\u001b[39;00m\n\u001b[1;32m      9\u001b[0m vertices \u001b[38;5;241m=\u001b[39m mesh\u001b[38;5;241m.\u001b[39mvertices\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/trimesh/exchange/load.py:114\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file_obj, file_type, resolver, force, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file_obj\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# parse the file arguments into clean loadable form\u001b[39;00m\n\u001b[1;32m    108\u001b[0m (\n\u001b[1;32m    109\u001b[0m     file_obj,  \u001b[38;5;66;03m# file- like object\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     file_type,  \u001b[38;5;66;03m# str, what kind of file\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     metadata,  \u001b[38;5;66;03m# dict, any metadata from file name\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     opened,  \u001b[38;5;66;03m# bool, did we open the file ourselves\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     resolver,  \u001b[38;5;66;03m# object to load referenced resources\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_file_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file_obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;66;03m# if we've been passed a dict treat it as kwargs\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/trimesh/exchange/load.py:606\u001b[0m, in \u001b[0;36m_parse_file_args\u001b[0;34m(file_obj, file_type, resolver, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse load_remote to load URL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_obj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m file_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 606\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring is not a file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_obj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    609\u001b[0m     file_type \u001b[38;5;241m=\u001b[39m file_obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
            "\u001b[0;31mValueError\u001b[0m: string is not a file: dataset/blockmesh_test/renders/3d_models_all.obj"
          ]
        }
      ],
      "source": [
        "!pip3 install ipyvolume trimesh pythreejs\n",
        "import trimesh\n",
        "\n",
        "folder = working_dir / 'renders'\n",
        "\n",
        "mesh = trimesh.load(f'{folder}/3d_models_all.obj')\n",
        "import ipyvolume as ipv\n",
        "\n",
        "vertices = mesh.vertices\n",
        "faces = mesh.faces\n",
        "\n",
        "fig = ipv.figure()\n",
        "ipv.plot_trisurf(vertices[:,0], vertices[:,1], vertices[:,2], triangles=faces)\n",
        "ipv.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oZP_cLvdRmb"
      },
      "source": [
        "**Text + prompt of tokens**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8GVxRnrdRmb"
      },
      "source": [
        "Grab fresh copy of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68Ni22DzdRmb"
      },
      "outputs": [],
      "source": [
        "dataset = MeshDataset.load(dataset_path)\n",
        "dataset.generate_codes(autoencoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBJxZBNUdRmb"
      },
      "source": [
        "**Prompt with 10% of codes/tokens BROKEN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0NTGFLFdRmb"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'texts'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[68], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mdata:\n\u001b[0;32m----> 7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtexts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m label:\n\u001b[1;32m      8\u001b[0m             num_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m token_length_procent)\n\u001b[1;32m     10\u001b[0m             texts\u001b[38;5;241m.\u001b[39mappend(item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtexts\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "\u001b[0;31mKeyError\u001b[0m: 'texts'"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "token_length_procent = 0.10\n",
        "codes = []\n",
        "texts = []\n",
        "for label in labels:\n",
        "    for item in dataset.data:\n",
        "        if item['texts'] == label:\n",
        "            num_tokens = int(item[\"codes\"].shape[0] * token_length_procent)\n",
        "\n",
        "            texts.append(item['texts'])\n",
        "            codes.append(item[\"codes\"].flatten()[:num_tokens].unsqueeze(0))\n",
        "            break\n",
        "\n",
        "folder = working_dir / f'renders/text+codes'\n",
        "obj_file_path = Path(folder)\n",
        "obj_file_path.mkdir(exist_ok = True, parents = True)\n",
        "\n",
        "coords = []\n",
        "\n",
        "\n",
        "\n",
        "for text, prompt in zip(texts, codes):\n",
        "    print(f\"Generating {text} with {prompt.shape[1]} tokens\")\n",
        "    faces_coordinates = transformer.generate(texts = [text],  prompt = prompt, temperature = 0)\n",
        "    coords.append(faces_coordinates)\n",
        "\n",
        "    obj_file_path = f'{folder}/{text}_{prompt.shape[1]}_tokens.obj'\n",
        "    write_mesh_output(obj_file_path, faces_coordinates)\n",
        "\n",
        "    print(obj_file_path)\n",
        "\n",
        "\n",
        "combind_mesh(f'{folder}/text+prompt_all.obj', coords)\n",
        "\n",
        "if text_coords is not None:\n",
        "    combind_mesh_with_rows(f'{folder}/both_verisons.obj', [text_coords , coords])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhBZsZJtdRmb"
      },
      "source": [
        "**Prompt with 0% to 80% of tokens BROKEN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXUYkxcwdRmc"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'codes'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[74], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mdata:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtexts\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m label:\n\u001b[0;32m---> 26\u001b[0m         num_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcodes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m token_length_procent)\n\u001b[1;32m     28\u001b[0m         texts\u001b[38;5;241m.\u001b[39mappend(item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtexts\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     29\u001b[0m         codes\u001b[38;5;241m.\u001b[39mappend(item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten()[:num_tokens]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n",
            "\u001b[0;31mKeyError\u001b[0m: 'codes'"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import trimesh\n",
        "from pathlib import Path\n",
        "\n",
        "def convert_to_obj(vertices, faces, output_file_path):\n",
        "    scene = trimesh.Scene()\n",
        "    mesh = trimesh.Trimesh(vertices=vertices, faces=faces)\n",
        "    scene.add_geometry(mesh)\n",
        "\n",
        "    with open(output_file_path, \"w\") as f:\n",
        "        f.write(scene.export(file_type=\"obj\"))\n",
        "\n",
        "def encode_to_pua(codes):\n",
        "    flat_codes = [item for sublist in codes for subsublist in sublist for item in subsublist]\n",
        "    return \"\".join(chr(code + 0xF0000) for code in flat_codes)\n",
        "\n",
        "jsonl_lines = []\n",
        "\n",
        "for token_length_procent in np.arange(0, 0.8, 0.1):\n",
        "    codes = []\n",
        "    texts = []\n",
        "    for label in labels:\n",
        "        for item in dataset.data:\n",
        "            if item['texts'] == label:\n",
        "                num_tokens = int(item[\"codes\"].shape[0] * token_length_procent)\n",
        "\n",
        "                texts.append(item['texts'])\n",
        "                codes.append(item[\"codes\"].flatten()[:num_tokens].unsqueeze(0))\n",
        "                break\n",
        "\n",
        "    coords = []\n",
        "    for text, code in zip(texts, codes):\n",
        "        print(f\"Generating {text} with {code.shape[1]} tokens\")\n",
        "        faces_coordinates = transformer.generate(texts=[text], prompt=code, temperature=0)\n",
        "        coords.append(faces_coordinates)\n",
        "\n",
        "        # Process mesh data inlined here\n",
        "        continuous_coors_list = [np_array.tolist() for np_array in faces_coordinates]\n",
        "        flat_list = [item for sublist in continuous_coors_list for item in sublist]\n",
        "        vertices = [vertex for sublist in flat_list for vertex in sublist]\n",
        "        faces = [[i, i + 1, i + 2] for i in range(0, len(vertices), 3)]\n",
        "\n",
        "        obj_filename = f'{text}_{code.shape[1]}_tokens.obj'\n",
        "        obj_file_path = folder / obj_filename\n",
        "        convert_to_obj(vertices, faces, obj_file_path)\n",
        "\n",
        "        encoded_codes = encode_to_pua(code.cpu().tolist())\n",
        "\n",
        "        with open(obj_file_path, \"r\") as file:\n",
        "            obj_contents = file.read()\n",
        "\n",
        "        # Append line to JSONL structure\n",
        "        jsonl_line = [\n",
        "            {\"role\": \"system\", \"content\": \"This assistant can understand 3D models using the meshgpt-pytorch Unicode plane 15 16384 item codebook for triangles and the .obj 3d format.\"},\n",
        "            {\"role\": \"user\", \"content\": encoded_codes},\n",
        "            {\"role\": \"assistant\", \"content\": obj_contents}\n",
        "        ]\n",
        "        jsonl_lines.append(jsonl_line)\n",
        "\n",
        "        print(obj_file_path)\n",
        "\n",
        "    mesh_rows.append(coords)\n",
        "    combind_mesh(f'{folder}/text+prompt_all_{token_length_procent}.obj', coords)\n",
        "\n",
        "combind_mesh_with_rows(f'{folder}/all.obj', mesh_rows)\n",
        "\n",
        "with open(\"chatml.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for item in jsonl_lines:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30627,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
